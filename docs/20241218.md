#### 在CDH中跑flink任务报错
```
第一次报错是因为yarn的内存设置太小   调大即可
第二次报错是因为刚创建的cdh，root用户没有对文件进行操作的权限
解决方法：
创建超级组，把root放到超级组中


1、在Linux执行如下命令增加supergroup
groupadd supergroup

2、如将用户root增加到supergroup中
usermod -a -G supergroup root

3、同步系统的权限信息到HDFS文件系统
sudo -u hdfs hdfs dfsadmin -refreshUserToGroupsMappings

4、查看属于supergroup用户组的用户
grep 'supergroup:' /etc/group

root实现对HDFS文件系统权限访问
https://blog.csdn.net/zhengqianjin/article/details/107268319
```
#### Spark 3.x版本的AOF机制
```
动态合并 Shuffle 分区（Coalescing Post Shuffle Partitions）：

当 Shuffle 操作完成后，AQE 可以根据 Map 输出的统计信息自动合并过小的分区，以减少 Reduce 阶段的分区数量，从而提高查询效率。这个特性通过配置 spark.sql.adaptive.coalescePartitions.enabled 开启，默认在 Spark 3.2.0 及以后的版本中是启用的
动态切换 Join 策略：

在 Spark 2.x 中，broadcast-hash join 只能通过参数控制，不易精确控制。Spark 3.x 的 AQE 能够根据运行时的统计信息自动将 sort-merge join 切换到 broadcast-hash join，优化性能。
动态优化数据倾斜的 Join：

在 Spark 2.x 中，需要手动处理数据倾斜问题。Spark 3.x 的 AQE 可以自动将倾斜的分区分成更小的分区进行 join，极大优化性能。
动态裁剪分区（Dynamic Partition Pruning）：

在 Spark 2.x 中，优化器很难在编译时确定哪些分区可以跳过不读，导致读了一些不需要的数据。Spark 3.x 的 AQE 会首先过滤维表，根据过滤后的结果找到只需要读事实表的哪些分区，提升性能。
自动处理数据倾斜：

AQE 自动检测并处理数据倾斜，通过将大型倾斜分区拆分为更小的分区，确保工作负载平衡，提高性能。
动态优化洗牌分区：

AQE 根据实际数据的大小动态调整洗牌分区的数量，优化并行性和开销之间的平衡，增强资源管理，减少内存使用和执行时间。
减少手动调优需求：


```

#### Flink提交以Application方式提交任务报错
```
1.设置hadoop classpath
2.yarn的资源不够，调大yarn的内存
yarn.nodemanager.resource.memory-mb	= 2048m
3.当你客户端的lib下有相关的包的时候，不需要打包进去，可能会引起依赖冲突
4.设置utf-8格式，如果不设置的话，涉及到的中文以问号形式显示

```
#### hbase的维度表支持事件事件吗
```
不支持
事件事件：是数据来的时间
```

#### java的设计模式
```
创建型模式，共五种：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。

结构型模式，共七种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。

行为型模式，共十一种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。

多态：方法的重写

```
